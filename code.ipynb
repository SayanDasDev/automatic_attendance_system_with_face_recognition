{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6067059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from insightface.app.common import Face\n",
    "from insightface.model_zoo import model_zoo\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1733aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2025-05-19 07:14:59.314160398 [E:onnxruntime:Default, provider_bridge_ort.cc:2195 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1778 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory\n",
      "\u001b[m\n",
      "\u001b[0;93m2025-05-19 07:14:59.314185332 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1055 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.\u001b[m\n",
      "\u001b[1;31m2025-05-19 07:14:59.535439799 [E:onnxruntime:Default, provider_bridge_ort.cc:2195 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1778 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcublasLt.so.12: cannot open shared object file: No such file or directory\n",
      "\u001b[m\n",
      "\u001b[0;93m2025-05-19 07:14:59.535472206 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:1055 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.\u001b[m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n"
     ]
    }
   ],
   "source": [
    "# detection and recognition models\n",
    "det_model_path = './models/buffalo_l/det_10g.onnx'  # RetinaFace-10GF for detection\n",
    "rec_model_path = './models/buffalo_l/w600k_r50.onnx'  # ResNet50@WebFace600K for recognition\n",
    "\n",
    "det_model = model_zoo.get_model(det_model_path)\n",
    "rec_model = model_zoo.get_model(rec_model_path)\n",
    "\n",
    "det_model.prepare(ctx_id=0, input_size=(640, 640), det_thres=0.5)\n",
    "rec_model.prepare(ctx_id=0, input_size=(640, 640), det_thres=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df1528d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings...\n",
      "All embeddings extracted and saved successfully.\n",
      "[[ 0.01218998  0.01847454 -0.0102439  ...  0.08157813  0.0472879\n",
      "  -0.0733004 ]\n",
      " [ 0.02232696 -0.01465663 -0.0834538  ...  0.06656986  0.07133806\n",
      "  -0.07881003]\n",
      " [ 0.03928491  0.00099033 -0.05734017 ...  0.08792619  0.08691135\n",
      "  -0.07987834]\n",
      " ...\n",
      " [ 0.03148594  0.07301585  0.07003179 ... -0.02915545 -0.01492532\n",
      "   0.02969946]\n",
      " [ 0.034522    0.08771636  0.08340845 ... -0.07423431 -0.01619307\n",
      "   0.04900846]\n",
      " [ 0.02049444  0.08852427  0.09765343 ... -0.05429428 -0.01989821\n",
      "   0.04645144]]\n"
     ]
    }
   ],
   "source": [
    "def extract_face_embeddings():\n",
    "    embeddings_path = './uploads/known_embeddings.npy'  # embeddings path\n",
    "    names_path = './uploads/known_names.pkl'  # names path\n",
    "\n",
    "    if os.path.exists(embeddings_path) and os.path.exists(names_path):\n",
    "        known_embeddings = np.load(embeddings_path)\n",
    "        with open(names_path, 'rb') as f:\n",
    "            known_names = pickle.load(f)\n",
    "    else:\n",
    "        known_embeddings = np.array([]).reshape(0, 512)  # empty array for embeddings\n",
    "        known_names = []  # empty list for names\n",
    "\n",
    "    # list all directories in the 'Dataset' folder\n",
    "    person_dirs = [d for d in os.listdir('./dataset') if os.path.isdir(os.path.join('./dataset', d))]\n",
    "    print(\"Extracting embeddings...\")\n",
    "\n",
    "    for person_name in person_dirs:\n",
    "        directory = f'./dataset/{person_name}'\n",
    "        img_paths = glob(f'{directory}/*.jpg')\n",
    "        new_embeddings = []  # list to store embeddings for each person\n",
    "\n",
    "        for idx, img_path in enumerate(img_paths):\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            bboxes, kpss = det_model.detect(img, max_num=0, metric='default')\n",
    "            if len(bboxes) == 0:\n",
    "                continue\n",
    "\n",
    "            # assuming the first bounding box is the correct one\n",
    "            bbox = bboxes[0, :4]\n",
    "            det_score = bboxes[0, 4]\n",
    "            kps = kpss[0]\n",
    "            face = Face(bbox=bbox, kps=kps, det_score=det_score)\n",
    "            rec_model.get(img, face)  # face embedding using the recognition model\n",
    "\n",
    "            if hasattr(face, 'normed_embedding'):\n",
    "                new_embeddings.append(face.normed_embedding)  # append the embedding\n",
    "            else:\n",
    "                print(f\"Failed to extract embedding for {img_path}\")\n",
    "\n",
    "        # if new embeddings are found for the person, add them to the list\n",
    "        if new_embeddings:\n",
    "            new_embeddings = np.vstack(new_embeddings)\n",
    "            known_embeddings = np.vstack([known_embeddings, new_embeddings])\n",
    "            known_names.extend([person_name] * new_embeddings.shape[0])\n",
    "\n",
    "    # Save embeddings and names\n",
    "    np.save(embeddings_path, known_embeddings)\n",
    "    with open(names_path, 'wb') as f:\n",
    "        pickle.dump(known_names, f)\n",
    "\n",
    "    # Print all embeddings at the end of the process\n",
    "    print(\"All embeddings extracted and saved successfully.\")\n",
    "    print(known_embeddings)\n",
    "\n",
    "extract_face_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9952e3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings():\n",
    "    embeddings_path = './uploads/known_embeddings.npy'\n",
    "    names_path = './uploads/known_names.pkl'\n",
    "\n",
    "    if os.path.exists(embeddings_path) and os.path.exists(names_path):\n",
    "        known_embeddings = np.load(embeddings_path)\n",
    "        with open(names_path, 'rb') as f:\n",
    "            known_names = pickle.load(f)\n",
    "        return known_embeddings, known_names\n",
    "    else:\n",
    "        print(\"No saved embeddings found.\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2415ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_match(embedding, known_embeddings, known_names, threshold=0.5):\n",
    "    scores = np.dot(embedding, known_embeddings.T) # cosine similarity between embeddings\n",
    "    scores = np.clip(scores, 0., 1.)\n",
    "    idx = np.argmax(scores) #  index of the highest score\n",
    "    score = scores[idx]\n",
    "    # return name if the score exceeds the threshold, otherwise return 'Unknown'\n",
    "    return known_names[idx] if score > threshold else 'Unknown'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12a7afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition(known_embeddings, known_names, threshold=0.5):\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Unable to open camera.\")\n",
    "        return\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame.\")\n",
    "            break\n",
    "\n",
    "        bboxes, kpss = det_model.detect(frame, max_num=0, metric='default')\n",
    "        if len(bboxes) > 0:\n",
    "            for i in range(len(bboxes)):\n",
    "                bbox = bboxes[i, :4]\n",
    "                kps = kpss[i]\n",
    "                face = Face(bbox=bbox, kps=kps, det_score=bboxes[i, 4])\n",
    "                rec_model.get(frame, face)\n",
    "                test_embedding = face.normed_embedding\n",
    "                pred_name = find_match(test_embedding, known_embeddings, known_names, threshold)\n",
    "\n",
    "                x1, y1, x2, y2 = map(int, bbox)\n",
    "                face_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                label = f\"{pred_name}\"\n",
    "\n",
    "                # Set color\n",
    "                if pred_name == 'Unknown':\n",
    "                    color = (0, 0, 255)\n",
    "                elif pred_name == 'sayan':\n",
    "                    color = (215, 168, 150)\n",
    "                else:\n",
    "                    color = (70, 255, 20)\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_DUPLEX, 0.6, color, 2)\n",
    "\n",
    "        cv2.imshow(\"Face Recognition + Mask Detection\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cf4eefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "known_embeddings, known_names = load_embeddings()\n",
    "if known_embeddings is not None and known_names is not None:\n",
    "    face_recognition(known_embeddings, known_names)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insight-face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
